<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice & Vision Assistant</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <style>
        /* CSS remains unchanged */
        :root {
            --primary: #6366f1;
            --primary-dark: #4f46e5;
            --secondary: #f472b6;
            --dark: #1e293b;
            --light: #f8fafc;
            --success: #22c55e;
            --danger: #ef4444;
            --warning: #f59e0b;
            --gradient: linear-gradient(135deg, var(--primary), var(--secondary));
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        body {
            background-color: var(--light);
            color: var(--dark);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 2rem 1rem;
            background-image: 
                radial-gradient(circle at 40% 20%, rgba(99, 102, 241, 0.1) 0%, transparent 30%),
                radial-gradient(circle at 80% 50%, rgba(244, 114, 182, 0.1) 0%, transparent 30%);
        }
        
        header {
            text-align: center;
            margin-bottom: 2rem;
            width: 100%;
        }
        
        h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            background: var(--gradient);
            -webkit-background-clip: text;
            background-clip: text;
            color: transparent;
            letter-spacing: -0.5px;
        }
        
        p.subtitle {
            color: #64748b;
            font-size: 1.1rem;
            max-width: 600px;
            margin: 0 auto;
        }
        
        .container {
            width: 100%;
            max-width: 800px;
            background-color: white;
            border-radius: 16px;
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.05);
            padding: 2rem;
            display: flex;
            flex-direction: column;
            gap: 2rem;
        }
        
        .section {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        
        .section-header {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            font-size: 1.25rem;
            font-weight: 600;
            color: var(--dark);
        }
        
        .section-icon {
            width: 36px;
            height: 36px;
            display: flex;
            align-items: center;
            justify-content: center;
            border-radius: 50%;
            background: var(--gradient);
            color: white;
        }
        
        .card {
            background-color: #f8fafc;
            border-radius: 12px;
            padding: 1.5rem;
        }
        
        /* Voice Recording Section */
        .mic-container {
            display: flex;
            align-items: center;
            gap: 1rem;
        }
        
        .mic-button {
            display: flex;
            align-items: center;
            justify-content: center;
            width: 60px;
            height: 60px;
            border-radius: 50%;
            border: none;
            background: var(--gradient);
            color: white;
            font-size: 1.5rem;
            cursor: pointer;
            box-shadow: 0 4px 12px rgba(99, 102, 241, 0.25);
            transition: all 0.3s ease;
        }
        
        .mic-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 16px rgba(99, 102, 241, 0.3);
        }
        
        .mic-button:active {
            transform: translateY(1px);
        }
        
        .mic-button.recording {
            background: var(--danger);
            box-shadow: 0 4px 12px rgba(239, 68, 68, 0.25);
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0% {
                box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.5);
            }
            70% {
                box-shadow: 0 0 0 10px rgba(239, 68, 68, 0);
            }
            100% {
                box-shadow: 0 0 0 0 rgba(239, 68, 68, 0);
            }
        }
        
        .recording-status {
            flex: 1;
            display: flex;
            flex-direction: column;
        }
        
        .status {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            font-weight: 500;
            margin-bottom: 0.25rem;
        }
        
        .status-indicator {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background-color: #cbd5e1;
        }
        
        .status-indicator.active {
            background-color: var(--success);
        }
        
        .status-indicator.recording {
            background-color: var(--danger);
            animation: blink 1s infinite;
        }
        
        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }
        
        .transcription-container {
            margin-top: 1rem;
            background-color: white;
            border-radius: 8px;
            padding: 1rem;
            min-height: 100px;
            border: 1px solid #e2e8f0;
        }
        
        .transcription-placeholder {
            color: #94a3b8;
            font-style: italic;
        }
        
        .transcribed {
            white-space: pre-wrap;
            line-height: 1.6;
        }
        
        /* Camera Section */
        .camera-controls {
            display: flex;
            gap: 1rem;
            margin-bottom: 1rem;
        }
        
        .camera-button {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.25rem;
            background: var(--gradient);
            color: white;
            border: none;
            border-radius: 8px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .camera-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(99, 102, 241, 0.2);
        }
        
        .camera-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 1rem;
            position: relative;
        }
        
        .video-wrapper {
            width: 100%;
            border-radius: 12px;
            overflow: hidden;
            background-color: #0f172a;
            position: relative;
            aspect-ratio: 16/9;
        }
        
        .video {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        .captured-image {
            max-width: 100%;
            border-radius: 12px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        }
        
        .image-preview {
            margin-top: 1rem;
            padding: 1rem;
            background-color: white;
            border-radius: 12px;
            border: 1px dashed #cbd5e1;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 1rem;
        }
        
        .preview-placeholder {
            color: #94a3b8;
            font-style: italic;
            text-align: center;
            padding: 2rem 0;
        }
        
        /* Send Query Section */
        .send-query {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 0.75rem;
            padding: 1rem 2rem;
            background: var(--gradient);
            color: white;
            border: none;
            border-radius: 50px;
            font-weight: 600;
            font-size: 1.1rem;
            cursor: pointer;
            margin: 1rem auto;
            transition: all 0.3s ease;
            box-shadow: 0 4px 12px rgba(99, 102, 241, 0.25);
        }
        
        .send-query:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 16px rgba(99, 102, 241, 0.3);
        }
        
        .send-query:active {
            transform: translateY(1px);
        }
        
        .send-query:disabled {
            background: #94a3b8;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }
        
        /* Response Section */
        .response-container {
            border-top: 1px solid #e2e8f0;
            padding-top: 1.5rem;
        }
        
        .response {
            background-color: white;
            border-radius: 12px;
            padding: 1.5rem;
            border: 1px solid #e2e8f0;
            min-height: 100px;
            line-height: 1.6;
        }
        
        .response:empty::before {
            content: "Your response will appear here...";
            color: #94a3b8;
            font-style: italic;
        }
        
        /* Divider */
        .divider {
            height: 1px;
            width: 100%;
            background-color: #e2e8f0;
            margin: 1rem 0;
        }
        
        /* Footer */
        footer {
            margin-top: 3rem;
            text-align: center;
            color: #64748b;
            font-size: 0.9rem;
        }
        
        /* Loading animation */
        .loading {
            display: inline-block;
            position: relative;
            width: 80px;
            height: 80px;
            margin: 0 auto;
        }
        
        .loading div {
            position: absolute;
            top: 33px;
            width: 13px;
            height: 13px;
            border-radius: 50%;
            background: var(--primary);
            animation-timing-function: cubic-bezier(0, 1, 1, 0);
        }
        
        .loading div:nth-child(1) {
            left: 8px;
            animation: loading1 0.6s infinite;
        }
        
        .loading div:nth-child(2) {
            left: 8px;
            animation: loading2 0.6s infinite;
        }
        
        .loading div:nth-child(3) {
            left: 32px;
            animation: loading2 0.6s infinite;
        }
        
        .loading div:nth-child(4) {
            left: 56px;
            animation: loading3 0.6s infinite;
        }
        
        @keyframes loading1 {
            0% { transform: scale(0); }
            100% { transform: scale(1); }
        }
        
        @keyframes loading3 {
            0% { transform: scale(1); }
            100% { transform: scale(0); }
        }
        
        @keyframes loading2 {
            0% { transform: translate(0, 0); }
            100% { transform: translate(24px, 0); }
        }
        
        /* Responsive */
        @media (max-width: 640px) {
            .container {
                padding: 1.5rem;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .camera-controls {
                flex-direction: column;
            }
            
            .send-query {
                width: 100%;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>Voice & Vision Assistant</h1>
        <p class="subtitle">Capture images, speak your query, and get intelligent responses instantly</p>
    </header>
    
    <div class="container">
        <!-- Voice Recording Section -->
        <div class="section">
            <div class="section-header">
                <div class="section-icon">
                    <i class="fas fa-microphone"></i>
                </div>
                <h2>Voice Input</h2>
            </div>
            
            <div class="card">
                <div class="mic-container">
                    <button class="mic-button">
                        <i class="fas fa-microphone"></i>
                    </button>
                    
                    <div class="recording-status">
                        <div class="status">
                            <span class="status-indicator"></span>
                            <span class="status-text">Microphone ready</span>
                        </div>
                        <small class="status-description">Click the microphone button to start recording</small>
                    </div>
                </div>
                
                <div class="transcription-container">
                    <div class="transcribed-content">
                        <div class="transcription-placeholder">Your speech will appear here after recording...</div>
                        <div class="transcribed"></div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Camera Section -->
        <div class="section">
            <div class="section-header">
                <div class="section-icon">
                    <i class="fas fa-camera"></i>
                </div>
                <h2>Camera Capture</h2>
            </div>
            
            <div class="card">
                <div class="camera-controls">
                    <button class="camera-button">
                        <i class="fas fa-camera"></i> Take Picture
                    </button>
                    <!-- Added front camera toggle button -->
                    <button class="camera-button camera-switch">
                        <i class="fas fa-sync-alt"></i> Switch Camera
                    </button>
                </div>
                
                <div class="camera-container">
                    <div class="video-wrapper">
                        <video class="video" autoplay></video>
                    </div>
                    <canvas class="canvas" style="display: none;"></canvas>
                    
                    <div class="image-preview">
                        <div class="preview-placeholder">Image preview will appear here after capture</div>
                        <img class="captured-image" alt="Captured Image" style="display: none;">
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Send Query Button -->
        <button class="send-query" disabled>
            <i class="fas fa-paper-plane"></i> Send Query
        </button>
        
        <!-- Response Section -->
        <div class="section response-container">
            <div class="section-header">
                <div class="section-icon">
                    <i class="fas fa-robot"></i>
                </div>
                <h2>Response</h2>
            </div>
            
            <div class="response"></div>
        </div>
    </div>
    
    <footer>
        <p>© 2025 Voice & Vision Assistant | All Rights Reserved</p>
    </footer>
    
    <script>
        // Elements
        const micButton = document.querySelector('.mic-button');
        const statusIndicator = document.querySelector('.status-indicator');
        const statusText = document.querySelector('.status-text');
        const statusDescription = document.querySelector('.status-description');
        const transcribedContent = document.querySelector('.transcribed');
        const transcriptionPlaceholder = document.querySelector('.transcription-placeholder');
        
        const cameraButton = document.querySelector('.camera-button');
        const cameraSwitchButton = document.querySelector('.camera-switch'); // Added camera switch button reference
        const video = document.querySelector('.video');
        const canvas = document.querySelector('.canvas');
        const capturedImage = document.querySelector('.captured-image');
        const previewPlaceholder = document.querySelector('.preview-placeholder');
        
        const sendQueryButton = document.querySelector('.send-query');
        const responseContainer = document.querySelector('.response');
        
        // State
        let isRecording = false;
        let mediaRecorder;
        let chunks = [];
        let hasCapturedImage = false;
        let hasTranscribedText = false;
        let currentStream = null; // Added to track current video stream
        let facingMode = "user"; // Added variable to track camera mode - "user" for front camera, "environment" for back camera
        
        // Initialize Camera with front-facing camera by default
        // CHANGED: Modified to use front camera (user-facing) by default
        function initializeCamera() {
            // Stop any existing stream
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
            }
            
            // Set camera constraints - "user" means front camera
            const constraints = {
                video: { 
                    facingMode: facingMode,
                    width: { ideal: 1280 },
                    height: { ideal: 720 }
                }
            };
            
            navigator.mediaDevices.getUserMedia(constraints)
                .then(stream => {
                    currentStream = stream; // Store reference to current stream
                    video.srcObject = stream;
                    
                    // Display camera mode indicator
                    statusText.innerText = facingMode === "user" ? 
                        "Front camera active" : 
                        "Back camera active";
                })
                .catch(error => {
                    console.error('Error accessing camera:', error);
                    statusText.innerText = 'Camera access denied';
                    statusText.style.color = 'var(--danger)';
                });
        }
        
        // Call initialize camera with front-facing camera
        initializeCamera();
        
        // Added camera switch functionality
        cameraSwitchButton.addEventListener('click', () => {
            // Toggle between front and back camera
            facingMode = facingMode === "user" ? "environment" : "user";
            
            // Update button text to indicate what will happen on next click
            cameraSwitchButton.innerHTML = facingMode === "user" ? 
                '<i class="fas fa-sync-alt"></i> Switch to Back Camera' : 
                '<i class="fas fa-sync-alt"></i> Switch to Front Camera';
            
            // Reinitialize camera with new facing mode
            initializeCamera();
        });
        
        // Initialize Microphone
        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
                mediaRecorder = new MediaRecorder(stream);
                
                mediaRecorder.ondataavailable = event => {
                    chunks.push(event.data);
                };
                
                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(chunks, { type: 'audio/ogg; codecs=opus' });
                    chunks = [];
                    
                    // Show processing state
                    statusText.innerText = 'Processing audio...';
                    statusDescription.innerText = 'Converting your speech to text';
                    
                    const formData = new FormData();
                    formData.append('audio', audioBlob, 'audio.ogg');
                    
                    // Simulate processing delay (remove in production)
                    setTimeout(() => {
                        // In a real app, this would be your actual API call:
                        fetch('/upload', {
                            method: 'POST',
                            body: formData
                        })
                        .then(response => response.json())
                        .then(data => { 
                            transcribedContent.innerText = data.text;
                        })
                        
                        // For demo, we'll just set some sample text
                        // const sampleText = "What is in this image?";
                        // transcribedContent.innerText = sampleText;
                        transcriptionPlaceholder.style.display = 'none';
                        
                        // Update states
                        statusText.innerText = 'Processing complete';
                        statusIndicator.classList.remove('recording');
                        statusIndicator.classList.add('active');
                        statusDescription.innerText = 'Speech converted to text successfully';
                        
                        hasTranscribedText = true;
                        updateSendButtonState();
                    }, 1500);
                };
            })
            .catch(error => {
                console.error('Error accessing microphone:', error);
                statusText.innerText = 'Microphone access denied';
                statusText.style.color = 'var(--danger)';
            });
        
        // Microphone button event
        micButton.addEventListener('click', () => {
            if (!isRecording) {
                // Start recording
                mediaRecorder.start();
                isRecording = true;
                
                // Update UI
                micButton.classList.add('recording');
                micButton.innerHTML = '<i class="fas fa-stop"></i>';
                statusIndicator.classList.add('recording');
                statusText.innerText = 'Recording in progress';
                statusDescription.innerText = 'Speak clearly into your microphone';
                
                // Clear previous transcription
                transcribedContent.innerText = '';
                transcriptionPlaceholder.style.display = 'block';
                hasTranscribedText = false;
                updateSendButtonState();
            } else {
                // Stop recording
                mediaRecorder.stop();
                isRecording = false;
                
                // Update UI
                micButton.classList.remove('recording');
                micButton.innerHTML = '<i class="fas fa-microphone"></i>';
                statusText.innerText = 'Processing audio...';
            }
        });
        
        // Camera button event
        cameraButton.addEventListener('click', () => {
            // Show processing animation
            previewPlaceholder.innerHTML = `
                <div class="loading">
                    <div></div><div></div><div></div><div></div>
                </div>
                <p>Processing capture...</p>
            `;
            
            // Capture image
            const context = canvas.getContext('2d');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            
            // CHANGED: For front camera (selfie mode), flip the image horizontally for natural mirror effect
            if (facingMode === "user") {
                context.translate(canvas.width, 0);
                context.scale(-1, 1);
            }
            
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            // Convert to data URL and display
            const imageDataURL = canvas.toDataURL('image/png');
            capturedImage.src = imageDataURL;
            
            // CHANGED: For front camera, mirror the display of the captured image
            if (facingMode === "user") {
                capturedImage.style.transform = "scaleX(-1)";
            } else {
                capturedImage.style.transform = "none";
            }
            
            // Show image after brief delay (simulating processing)
            setTimeout(() => {
                capturedImage.style.display = 'block';
                previewPlaceholder.style.display = 'none';
                hasCapturedImage = true;
                updateSendButtonState();
            }, 800);
        });
        
        // Update send button state
        function updateSendButtonState() {
            if (hasCapturedImage && hasTranscribedText) {
                sendQueryButton.disabled = false;
            } else {
                sendQueryButton.disabled = true;
            }
        }
        
        // Send query button event
        sendQueryButton.addEventListener('click', async() => {
            // Show loading state
            responseContainer.innerHTML = `
                <div style="display: flex; flex-direction: column; align-items: center; justify-content: center; padding: 2rem 0;">
                    <div class="loading">
                        <div></div><div></div><div></div><div></div>
                    </div>
                    <p style="margin-top: 1rem; color: #64748b;">Analyzing your image and query...</p>
                </div>
            `;
            
            // Prepare form data
            const formData = new FormData();
            formData.append('image', capturedImage.src);
            formData.append('user_query', transcribedContent.innerText);
            
            try {
                // In a real app, you would do this API call:
                const response = await fetch('https://serverless.roboflow.com/infer/workflows/rishav-qz1u7/false-people', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        api_key: '5XagyPRtCr1rJQzvdDwl',
                        inputs: {
                            "image": {"type": "url", "value": capturedImage.src},
                        }
                    })
                });
                
                // Process result
                const result = await response.json();
                console.log(result);
                
                // Show response after a brief delay
                setTimeout(() => {
                    try {
                        const outputText = result.outputs[0].llama_vision.output;
                        responseContainer.innerHTML = `<p>${outputText}</p>`;
                    } catch (error) {
                        // Fallback for demo or if API fails
                        responseContainer.innerHTML = `
                            <p>I can see a person standing in what appears to be an indoor environment. 
                            The lighting is good and the image quality is clear. There are no obvious 
                            hazards or dangers visible in this scene.</p>
                        `;
                    }
                }, 1500);
                
            } catch (error) {
                console.error('Error sending query:', error);
                
                // Fallback response for demo
                setTimeout(() => {
                    responseContainer.innerHTML = `
                        <p>I can see a person standing in what appears to be an indoor environment. 
                        The lighting is good and the image quality is clear. There are no obvious 
                        hazards or dangers visible in this scene.</p>
                    `;
                }, 1500);
            }
        });
    </script>
</body>
</html>